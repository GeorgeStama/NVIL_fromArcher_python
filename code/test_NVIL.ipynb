{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# load Python/Theano stuff\n",
    "# Show figures inline with the code\n",
    "%matplotlib inline   \n",
    "\n",
    "import theano\n",
    "import theano.tensor as T\n",
    "import theano.tensor.nlinalg as Tla\n",
    "import lasagne       # the library we're using for NN's\n",
    "# import the nonlinearities we might use \n",
    "from lasagne.nonlinearities import leaky_rectify, softmax, linear, tanh, rectify\n",
    "from theano.tensor.shared_randomstreams import RandomStreams\n",
    "import numpy as np\n",
    "from numpy.random import *\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import cPickle\n",
    "import sys\n",
    "\n",
    "# import kmeans clustering algorithm from scikit-learn\n",
    "from sklearn.cluster import KMeans \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Load our code\n",
    "\n",
    "# Add all the paths that should matter right now\n",
    "sys.path.append('lib/') \n",
    "from GenerativeModel import *       # Class file for generative models. \n",
    "from RecognitionModel import *      # Class file for recognition models\n",
    "from NVIL import *                  # The meat of the algorithm - define the cost function and initialize Gen/Rec model\n",
    "\n",
    "# import our covariance-plotting software\n",
    "from plot_cov import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Use the fast compile option\n",
    "#theano.config.optimizer = 'fast_compile' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Choose Simulation Parameters and Generate Data\n",
    "xDim = 3 # number of latent classes\n",
    "yDim = 2 # dimensionality of Gaussian observations\n",
    "_N = 2500 # number of datapoints to generate\n",
    "gmm = MixtureOfGaussians(dict([]), xDim, yDim)  # instantiate our 'true' generative model\n",
    "[xsamp, ysamp] = gmm.sampleXY(_N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Set up Lasagne Recognition Network \n",
    "rec_is_training = theano.shared(value = 1) \n",
    "rec_nn = lasagne.layers.InputLayer((None, yDim))\n",
    "rec_nn = lasagne.layers.DenseLayer(rec_nn, 100, nonlinearity=leaky_rectify, W=lasagne.init.Orthogonal())\n",
    "rec_nn = lasagne.layers.DenseLayer(rec_nn, xDim, nonlinearity=softmax, W=lasagne.init.Orthogonal(), b=-5*np.ones(xDim, dtype=theano.config.floatX))\n",
    "NN_Params = dict([('network', rec_nn)])\n",
    "recDict = dict([('NN_Params'     , NN_Params)\n",
    "                ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2500, 2)\n"
     ]
    }
   ],
   "source": [
    "# Now we get to try it!\n",
    "\n",
    "# center our simluated data around the mean\n",
    "ysamp_mean = ysamp.mean(axis=0, dtype=theano.config.floatX)\n",
    "ytrain = ysamp - ysamp_mean\n",
    "\n",
    "# construct a BuildModel object that represents the method\n",
    "opt_params = dict({'c0': -0.0, 'v0': 1.0, 'alpha': 0.9})\n",
    "model = BuildModel(opt_params, dict([]), MixtureOfGaussians, recDict, GMMRecognition, xDim, yDim, nCUnits = 100)\n",
    "\n",
    "# Initialize generative model at the k-means solution\n",
    "km = KMeans(n_clusters=xDim, n_init=10, max_iter=500)\n",
    "kmpred = km.fit_predict(ytrain)\n",
    "\n",
    "km_mu = np.zeros([xDim, yDim])\n",
    "km_chol = np.zeros([xDim, yDim, yDim])\n",
    "for cl in np.unique(kmpred):\n",
    "    km_mu[cl] = ytrain[kmpred == cl].mean(axis=0)\n",
    "    km_chol[cl] = np.linalg.cholesky(np.cov(ytrain[kmpred == cl].T))\n",
    "    \n",
    "model.mprior.mu.set_value(km_mu.astype(theano.config.floatX))\n",
    "model.mprior.RChol.set_value(km_chol.astype(theano.config.floatX))\n",
    "\n",
    "km_pi = np.histogram(kmpred,bins=xDim)[0]/(1.0*kmpred.shape[0])\n",
    "model.mprior.pi_un.set_value(km_pi.astype(theano.config.floatX))\n",
    "\n",
    "# Initialize with *true* means and covariances\n",
    "# model.mprior.mu.set_value(gmm.mu.get_value()-ysamp_mean)\n",
    "# model.mprior.RChol.set_value(gmm.RChol.get_value())\n",
    "# model.mprior.pi_un.set_value(gmm.pi_un.get_value())\n",
    "\n",
    "print ysamp.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.00%\n",
      "(c,v,L): (-0.000000,1.000000,-49.737572)\n",
      "\n",
      "(c,v,L): (-13.624687,493.738892,-21.270672)\n",
      "\n",
      "(c,v,L): (-16.857901,608.627319,-47.895481)\n",
      "\n",
      "(c,v,L): (-19.395361,778.016357,-21.273934)\n",
      "\n",
      "(c,v,L): (-20.690432,639.348450,-16.088428)\n",
      "\n",
      "(c,v,L): (-22.701141,619.722839,-4.689969)\n",
      "\n",
      "(c,v,L): (-19.747732,573.690552,-24.434265)\n",
      "\n",
      "(c,v,L): (-15.991956,442.958618,-20.887612)\n",
      "\n",
      "(c,v,L): (-15.205685,360.078339,-11.127972)\n",
      "\n",
      "(c,v,L): (-15.107061,287.115540,-4.505026)\n",
      "\n",
      "(c,v,L): (-14.389825,338.490204,-2.749216)\n",
      "\n",
      "(c,v,L): (-12.464176,319.255554,-9.688044)\n",
      "\n",
      "(c,v,L): (-13.615008,288.402832,-8.961222)\n",
      "\n",
      "(c,v,L): (-12.110258,250.439163,-9.581438)\n",
      "\n",
      "(c,v,L): (-12.503030,261.209961,-10.775481)\n",
      "\n",
      "(c,v,L): (-13.432916,279.752502,-13.453026)\n",
      "\n",
      "(c,v,L): (-13.324061,264.187500,-17.864207)\n",
      "\n",
      "(c,v,L): (-10.270400,162.126816,-4.931938)\n",
      "\n",
      "(c,v,L): (-12.002291,210.199448,-18.288985)\n",
      "\n",
      "(c,v,L): (-9.873152,144.449890,-5.740092)\n",
      "\n",
      "(c,v,L): (-8.678061,124.000336,-3.283193)\n",
      "\n",
      "(c,v,L): (-8.338475,115.507927,-7.808617)\n",
      "\n",
      "(c,v,L): (-11.393260,174.664810,-10.599424)\n",
      "\n",
      "(c,v,L): (-8.703773,101.908173,-4.933594)\n",
      "\n",
      "(c,v,L): (-8.644063,128.529129,-6.501189)\n",
      "\n",
      "20.00%\n",
      "(c,v,L): (-7.800912,99.885674,-5.081755)\n",
      "\n",
      "(c,v,L): (-7.066769,100.881317,-3.974011)\n",
      "\n",
      "(c,v,L): (-7.402954,102.909592,-4.295578)\n",
      "\n",
      "(c,v,L): (-6.355639,102.353569,-18.129358)\n",
      "\n",
      "(c,v,L): (-6.988206,116.569496,-6.327279)\n",
      "\n",
      "(c,v,L): (-6.243934,92.748383,-9.091037)\n",
      "\n",
      "(c,v,L): (-6.642777,71.339798,-7.001253)\n",
      "\n",
      "(c,v,L): (-7.075717,101.392975,-9.135447)\n",
      "\n",
      "(c,v,L): (-5.792230,81.400177,-7.854903)\n",
      "\n",
      "(c,v,L): (-5.480516,63.884468,-2.868885)\n",
      "\n",
      "(c,v,L): (-5.500943,57.325371,-5.681036)\n",
      "\n",
      "(c,v,L): (-5.840867,60.903275,-2.396614)\n",
      "\n",
      "(c,v,L): (-5.454395,63.578350,-5.190687)\n",
      "\n",
      "(c,v,L): (-5.561487,67.228363,-10.709344)\n",
      "\n",
      "(c,v,L): (-5.394085,51.005058,-7.596490)\n",
      "\n",
      "(c,v,L): (-5.135267,53.298000,-6.376382)\n",
      "\n",
      "(c,v,L): (-5.598027,59.815903,-0.516915)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Fit the model\n",
    "costs = model.fit(ytrain, batch_size = 10, max_epochs=5, learning_rate = 3e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Plot ELBO (variational lower bound objective) against iteration\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(costs[:100])\n",
    "plt.xlabel('iteration')\n",
    "plt.ylabel('ELBO')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "clr = ['b', 'r', 'c','g','m','o']\n",
    "\n",
    "plt.figure()\n",
    "plt.subplot(121)\n",
    "plt.plot(ysamp[:,0], ysamp[:,1],'k.', alpha=.1)\n",
    "plt.hold('on')\n",
    "for ii in xrange(xDim):\n",
    "    Rc= gmm.RChol[ii].eval()\n",
    "    plot_cov_ellipse(Rc.dot(Rc.T), gmm.mu[ii].eval(), nstd=2, color=clr[ii%5], alpha=.3)\n",
    "    \n",
    "plt.title('True Distribution')\n",
    "plt.ylabel(r'$x_0$')\n",
    "plt.xlabel(r'$x_1$')\n",
    "\n",
    "plt.subplot(122)\n",
    "plt.hold('on')\n",
    "plt.plot(ytrain[:,0], ytrain[:,1],'k.', alpha=.1)\n",
    "for ii in xrange(xDim):\n",
    "    Rc= model.mprior.RChol[ii].eval()\n",
    "    plot_cov_ellipse(Rc.dot(Rc.T), model.mprior.mu[ii].eval(), nstd=2, color=clr[ii%5], alpha=.3)\n",
    "    \n",
    "plt.title('Learned Distributions')    \n",
    "plt.ylabel(r'$x_0$')\n",
    "plt.xlabel(r'$x_1$')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "xlbl = xsamp.nonzero()[1]\n",
    "#learned_lbl = model.mrec.h.eval({model.Y:ytrain}).argmax(axis=1)\n",
    "#learned_lbl = model.mrec.getSample(ytrain).argmax(axis=1)\n",
    "learned_lbl = model.mrec.h.argmax(axis=1).eval({model.Y:ytrain})\n",
    "\n",
    "clr = ['b', 'r', 'c','g','m','o']\n",
    "\n",
    "plt.figure()\n",
    "for ii in np.random.permutation(xrange(500)):\n",
    "    plt.subplot(121)\n",
    "    plt.hold('on')\n",
    "    plt.plot(ysamp[ii,0] ,ysamp[ii,1],'.', color = clr[xlbl[ii]%5])\n",
    "    plt.subplot(122)\n",
    "    plt.hold('on')\n",
    "    plt.plot(ysamp[ii,0] ,ysamp[ii,1],'.', color = clr[learned_lbl[ii]%5])\n",
    "    \n",
    "plt.subplot(121)\n",
    "plt.title('True Label')\n",
    "plt.ylabel(r'$x_0$')\n",
    "plt.xlabel(r'$x_1$')\n",
    "plt.subplot(122)\n",
    "plt.title('Inferred Label')\n",
    "plt.ylabel(r'$x_0$')\n",
    "plt.xlabel(r'$x_1$')\n",
    "    \n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "n = 25\n",
    "\n",
    "x = np.linspace(-3, 3, n)\n",
    "y = np.linspace(-3, 3, n)\n",
    "xv, yv = np.meshgrid(x, y)\n",
    "grid= np.vstack([xv.flatten(), yv.flatten()]).T\n",
    "\n",
    "gridlabel = model.mrec.getSample(grid.astype(theano.config.floatX)).argmax(axis=1)\n",
    "\n",
    "plt.figure()\n",
    "plt.hold('on')\n",
    "for ii in xrange(n*n):\n",
    "    plt.plot(grid[ii,0] ,grid[ii,1],'.', color = clr[gridlabel[ii]%5])\n",
    "plt.ylabel(r'$x_0$')\n",
    "plt.xlabel(r'$x_1$')\n",
    "plt.title('Highest-Probability Label Over Sampled Grid')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
